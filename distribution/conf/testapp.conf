spark {
  spark.streaming.batchDuration = 5
  spark.sql.catalogImplementation = "hive"
  spark.executor.instances = 4
  spark.executor.cores = 4
  spark.driver.memory = 2g
  spark.executor.memory = "8g"
}
input {
  hive {
      pre_sql = "select 1000 as momid, '2020-06-28' as dt ,168168 as app_source,10003 as amount from nonstruct_data.dwd_imagenet_wnid_url where dt='2020-06-28' limit 10"
      table_name = "mytable"
  }
}
filter {}
output {
  mysql {
    "password":"testmysql",
    "save_mode":"overwrite",
    "update_fields": "momid,dt,app_source,amount",
    "useProxy":false,
    "user":"root",
    "url":"jdbc:mysql://10.0.0.0:6607/test?autoReconnect=true&useSSL=false",
    "table":"waterdrop_test_zyw",
    "presql":""
}
}