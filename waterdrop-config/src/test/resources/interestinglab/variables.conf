spark {
  spark.streaming.batchDuration = 5

  spark.app.name = "Waterdrop"
  spark.executor.instances = 2
  spark.executor.cores = 1
  spark.executor.memory = "1g"
}

input {
  fakestream {
    content = [
      "20190318, beijing, first message",
      "20190319, shanghai, second message",
      "20190318, shanghai, third message"
    ]
    rate = 1
  }
}

filter {
  split {
    fields = ["dt", "city", "msg"]
    delimiter = ","
  }

  sql {
    table_name = "user_view"
    sql = "select * from user_view where city = '"${city2}"'"
    result_table_name = "result1"
  }

  sql {
    table_name = "user_view"
    sql = "select * from user_view where dt = '"${dt}"'"
    result_table_name = "result2"
  }
}

output {
  stdout {
    source_table_name="result1"
  }

  stdout {
  }
}
